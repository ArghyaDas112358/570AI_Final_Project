{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09d525f-2bae-44e3-833f-376d07f96cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 02:35:21.362869: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-03 02:35:21.362931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-03 02:35:21.364399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 02:35:21.372062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 02:35:22.258769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# python based\n",
    "import tensorflow as tf\n",
    "# print(\"tensorflow version:\",tf.__version__)\n",
    "# print(\"tf.keras version:\",tf.keras.__version__)\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom \n",
    "from loss import *\n",
    "from omodels import * # old model (with L1 and L2 regularizers)\n",
    "from OptimizedDataGenerator import OptimizedDataGenerator\n",
    "import mdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d6512e-f169-4c9c-b327-e0428312a030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/depot/cms/users/das214/dataset8/unflipped/recon3D/\n",
      "/depot/cms/users/das214/dataset8/unflipped/labels/\n",
      "160\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "# dataset_path = '/depot/cms/users/dkondra/smart-pixels/dataset8/unflipped-positive'\n",
    "dataset_path = '/depot/cms/users/das214/dataset8/unflipped'\n",
    "data_directory_path = os.path.join(dataset_path, 'recon3D/')\n",
    "labels_directory_path = os.path.join(dataset_path, 'labels/')\n",
    "\n",
    "data_files_path_list = [os.path.join(data_directory_path, f) for f in os.listdir(data_directory_path)]\n",
    "labels_files_path_list = [os.path.join(labels_directory_path, f) for f in os.listdir(labels_directory_path)]\n",
    "\n",
    "data_files_path_list = np.sort(data_files_path_list)\n",
    "labels_files_path_list = np.sort(labels_files_path_list)\n",
    "\n",
    "print(data_directory_path)\n",
    "print(labels_directory_path)\n",
    "print(len(data_files_path_list))\n",
    "print(len(labels_files_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41e495d-c5f6-4423-813e-6971e12da9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = Path(\"./\").resolve()\n",
    "\n",
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 142\n",
    "val_file_size = 6\n",
    "epochs=1000\n",
    "\n",
    "# batch_size = 500\n",
    "# val_batch_size = 500\n",
    "# train_file_size = 20 # controls number of train files used -> seem to run into a problem using >=50 files maybe with memory\n",
    "# val_file_size = 6 # controls number of validation files used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc9a559-1759-4d4f-b3be-27ccce4d7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/das214/MDMM\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)\n",
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e073a9-dea8-4522-aaff-b06aecf74552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tf records directory\n",
    "stamp = '%08x' % random.randrange(16**8)\n",
    "stamp = 1\n",
    "tfrecords_dir_train = Path(output_directory, f\"tfrecords_train_{stamp}\").resolve()\n",
    "tfrecords_dir_validation = Path(output_directory, f\"tfrecords_validation_{stamp}\").resolve()\n",
    "\n",
    "tfrecords_dir_train = \"/depot/cms/users/das214/tfrecords_2t_train_d8\"\n",
    "tfrecords_dir_validation = \"/depot/cms/users/das214/tfrecords_2t_val_d8\"\n",
    "\n",
    "# clean up tf records\n",
    "# utils.safe_remove_directory(tfrecords_dir_train)\n",
    "# utils.safe_remove_directory(tfrecords_dir_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877986e5-4d02-48b9-8ebf-4de28c98420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# validation_generator = OptimizedDataGenerator(\n",
    "#     data_directory_path = data_directory_path,\n",
    "#     labels_directory_path = labels_directory_path,\n",
    "#     is_directory_recursive = False,\n",
    "#     file_type = \"parquet\",\n",
    "#     data_format = \"3D\",\n",
    "#     batch_size = val_batch_size,\n",
    "#     file_count = val_file_size,\n",
    "#     to_standardize= True,\n",
    "#     include_y_local= False,\n",
    "#     labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "#     input_shape = (2,13,21), # (20,13,21),\n",
    "#     transpose = (0,2,3,1),\n",
    "#     shuffle = False, \n",
    "#     files_from_end=True,\n",
    "\n",
    "#     tfrecords_dir = tfrecords_dir_validation,\n",
    "#     use_time_stamps = [0, 19], #-1\n",
    "#     max_workers = 2\n",
    "# )\n",
    "\n",
    "# print(\"--- Validation generator %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad0d6b9-6c0a-47f2-a0ab-b84fcc9093b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # training generator\n",
    "# start_time = time.time()\n",
    "# training_generator = OptimizedDataGenerator(\n",
    "#     data_directory_path = data_directory_path,\n",
    "#     labels_directory_path = labels_directory_path,\n",
    "#     is_directory_recursive = False,\n",
    "#     file_type = \"parquet\",\n",
    "#     data_format = \"3D\",\n",
    "#     batch_size = batch_size,\n",
    "#     file_count = train_file_size,\n",
    "#     to_standardize= True,\n",
    "#     include_y_local= False,\n",
    "#     labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "#     input_shape = (2,13,21), # (20,13,21),\n",
    "#     transpose = (0,2,3,1),\n",
    "#     shuffle = False, # True \n",
    "\n",
    "#     tfrecords_dir = tfrecords_dir_train,\n",
    "#     use_time_stamps = [0, 19], #-1\n",
    "#     max_workers = 2\n",
    "# )\n",
    "# print(\"--- Training generator %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1320dddd-3da1-4624-b681-6daf95fb099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "training_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_train,#'/home/das214/dataset8_analysis/semiparametric/timeslices-2/neurips-3x3-2conv/tfrecords_train_1'\n",
    "    shuffle = True,\n",
    "    seed = 13,\n",
    "    quantize = True\n",
    ")\n",
    "\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_validation, #'/home/das214/dataset8_analysis/semiparametric/timeslices-2/neurips-3x3-2conv/tfrecords_validation_1'\n",
    "    shuffle = True,\n",
    "    seed = 13,\n",
    "    quantize = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a094602d-5ec2-4de4-bb64-83508c204aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 02:35:25.163635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37097 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB MIG 7g.40gb, pci bus id: 0000:21:00.0, compute capability: 8.0\n",
      "2024-12-03 02:35:25.429607: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "input_shape = (13, 21, 2)\n",
    "model = CreateModel(input_shape, n_filters=5, pool_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615d5be2-ba5c-4dcf-a8ac-d43ccad672d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3\n",
    "target_sparsity = 0.5\n",
    "scale = 1.0\n",
    "damping = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f651d08-c21f-4434-97c5-13f3a83ba3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sparsity after initialization: 0.005\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# initialization should not really matter\n",
    "def calculate_sparsity(model, epsilon):\n",
    "    zero_count = 0\n",
    "    total_count = 0\n",
    "    for layer in model.layers:\n",
    "        if layer.weights:\n",
    "            weights = layer.get_weights()[0]\n",
    "            zero_count += np.sum(np.isclose(weights, 0, atol=epsilon))\n",
    "            total_count += weights.size\n",
    "    return zero_count / total_count if total_count > 0 else 0\n",
    "\n",
    "new_sparsity = calculate_sparsity(model, epsilon)\n",
    "print(f\"Model sparsity after initialization: {new_sparsity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07cbc512-2105-4409-9772-f9eb6ab364fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 2)]       0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         33        \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2029 (7.93 KB)\n",
      "Trainable params: 2029 (7.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=custom_loss\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f316a1-ea46-47b7-9367-1018c898e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "os.makedirs(\"trained_models_non_mdmm\", exist_ok=True)\n",
    "base_dir = f'./trained_models_non_mdmm/model-{fingerprint}-checkpoints'\n",
    "os.makedirs(base_dir, exist_ok=True)  \n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72d78bd7-83af-4434-8e82-7a55067426b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636eb1c6\n"
     ]
    }
   ],
   "source": [
    "print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c5e964-602b-432b-a735-50c38b02e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "early_stopping_patience = 50\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        checkpoints = [f for f in os.listdir(base_dir) if f.startswith('weights')]\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints.sort()\n",
    "            for checkpoint in checkpoints[:-1]:\n",
    "                os.remove(os.path.join(base_dir, checkpoint))\n",
    "\n",
    "es = EarlyStopping(patience=early_stopping_patience, restore_best_weights=True)\n",
    "\n",
    "mcp = CustomModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(f'{base_dir}/training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84f1a87d-cd6e-44a2-9ac8-b3258a16a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummy, _ = training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea6e0b42-cf16-491b-b0e7-0d9bd785431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "class NormsAndLossLogger(Callback):\n",
    "    def __init__(self, model, epsilon):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = [] \n",
    "        self.lmbdas = []\n",
    "        self.sparsity = []\n",
    "        self.norms = []\n",
    "        self.inf = []\n",
    "        self.layers = [l for l in model.layers if l.weights]\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.losses.append(logs.get('loss_obj', 0))  # Default to 0 if key is missing\n",
    "        \n",
    "        current_sparsity = []\n",
    "        current_norms = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            weights = layer.weights[0]\n",
    "            abs_weights = tf.abs(weights)\n",
    "            sparsity = tf.reduce_mean(tf.cast(tf.less_equal(abs_weights, self.epsilon), tf.float32))\n",
    "            norm = tf.reduce_mean(abs_weights)\n",
    "            \n",
    "            current_sparsity.append(sparsity)\n",
    "            current_norms.append(norm)\n",
    "\n",
    "        self.norms.append(current_norms)\n",
    "        self.sparsity.append(current_sparsity)\n",
    "\n",
    "        current_lmbdas = []\n",
    "        self.lmbdas.append(current_lmbdas)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_norms = self.norms[-1] if self.norms else []\n",
    "        current_sparsity = self.sparsity[-1] if self.sparsity else []\n",
    "        current_lmbdas = self.lmbdas[-1] if self.lmbdas else []\n",
    "        # current_inf = self.inf[-1] if self.inf else []\n",
    "        self.val_losses.append(logs.get('val_loss', 0))\n",
    "        \n",
    "        zero_count = 0\n",
    "        total_count = 0\n",
    "        for layer in self.model.layers:\n",
    "            if layer.weights:\n",
    "                weights = tf.convert_to_tensor(layer.get_weights()[0])\n",
    "                abs_weights = tf.abs(weights)\n",
    "                zero_count += tf.reduce_sum(tf.cast(tf.less_equal(abs_weights, self.epsilon), tf.int32))\n",
    "                total_count += tf.size(weights)\n",
    "    \n",
    "        overall_sparsity = zero_count / total_count if total_count > 0 else 0\n",
    "        \n",
    "        # Print layer-wise sparsities, overall sparsity, and other details\n",
    "        print(f\"\\nEpoch {epoch + 1}:\")\n",
    "        print(\"Layer sparsities:\", \", \".join([f\"{s.numpy():.4f}\" for s in current_sparsity]))\n",
    "        print(f\"Overall sparsity: {overall_sparsity.numpy():.4f}\")\n",
    "        print(\"Lambdas:\", [\n",
    "            l.numpy() if isinstance(l, tf.Tensor) else l for l in current_lmbdas\n",
    "        ])\n",
    "        print(\"Validation Loss:\", self.val_losses[-1])\n",
    "        print()\n",
    "\n",
    "\n",
    "norms_and_loss_logger = NormsAndLossLogger(model, epsilon=epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24061ace-13f8-456b-a33c-b80620231e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -16267.2256\n",
      "Epoch 1: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.01-t-16267.23-v-16969.82.hdf5\n",
      "\n",
      "Epoch 1:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -16969.82421875\n",
      "\n",
      "1419/1419 [==============================] - 110s 75ms/step - loss: -16267.2256 - val_loss: -16969.8242\n",
      "Epoch 2/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -17324.0020\n",
      "Epoch 2: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.02-t-17324.00-v-16920.08.hdf5\n",
      "\n",
      "Epoch 2:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0063, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -16920.078125\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -17324.0020 - val_loss: -16920.0781\n",
      "Epoch 3/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -18380.3223\n",
      "Epoch 3: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.03-t-18380.32-v-18503.11.hdf5\n",
      "\n",
      "Epoch 3:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -18503.109375\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -18380.3223 - val_loss: -18503.1094\n",
      "Epoch 4/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -18487.9707\n",
      "Epoch 4: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.04-t-18487.97-v-18486.23.hdf5\n",
      "\n",
      "Epoch 4:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -18486.232421875\n",
      "\n",
      "1419/1419 [==============================] - 108s 76ms/step - loss: -18487.9707 - val_loss: -18486.2324\n",
      "Epoch 5/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -18619.9023\n",
      "Epoch 5: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.05-t-18619.90-v-17269.55.hdf5\n",
      "\n",
      "Epoch 5:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -17269.548828125\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -18619.9023 - val_loss: -17269.5488\n",
      "Epoch 6/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19161.5957\n",
      "Epoch 6: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.06-t-19161.60-v-18233.55.hdf5\n",
      "\n",
      "Epoch 6:\n",
      "Layer sparsities: 0.0556, 0.0000, 0.0097, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0097\n",
      "Lambdas: []\n",
      "Validation Loss: -18233.5546875\n",
      "\n",
      "1419/1419 [==============================] - 110s 77ms/step - loss: -19161.5957 - val_loss: -18233.5547\n",
      "Epoch 7/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19259.8945\n",
      "Epoch 7: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.07-t-19259.89-v-20321.78.hdf5\n",
      "\n",
      "Epoch 7:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0069, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -20321.779296875\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -19259.8945 - val_loss: -20321.7793\n",
      "Epoch 8/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19477.0723\n",
      "Epoch 8: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.08-t-19477.07-v-20054.37.hdf5\n",
      "\n",
      "Epoch 8:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -20054.37109375\n",
      "\n",
      "1419/1419 [==============================] - 108s 76ms/step - loss: -19477.0723 - val_loss: -20054.3711\n",
      "Epoch 9/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19568.8496\n",
      "Epoch 9: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.09-t-19568.85-v-19047.30.hdf5\n",
      "\n",
      "Epoch 9:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0020\n",
      "Lambdas: []\n",
      "Validation Loss: -19047.30078125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -19568.8496 - val_loss: -19047.3008\n",
      "Epoch 10/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19351.5762\n",
      "Epoch 10: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.10-t-19351.58-v-18976.74.hdf5\n",
      "\n",
      "Epoch 10:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -18976.744140625\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -19351.5762 - val_loss: -18976.7441\n",
      "Epoch 11/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -19777.8105\n",
      "Epoch 11: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.11-t-19777.81-v-20267.64.hdf5\n",
      "\n",
      "Epoch 11:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -20267.638671875\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -19777.8105 - val_loss: -20267.6387\n",
      "Epoch 12/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -20114.6641\n",
      "Epoch 12: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.12-t-20114.66-v-20469.11.hdf5\n",
      "\n",
      "Epoch 12:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -20469.111328125\n",
      "\n",
      "1419/1419 [==============================] - 108s 76ms/step - loss: -20114.6641 - val_loss: -20469.1113\n",
      "Epoch 13/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -20201.3438\n",
      "Epoch 13: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.13-t-20201.34-v-19741.13.hdf5\n",
      "\n",
      "Epoch 13:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -19741.12890625\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -20201.3438 - val_loss: -19741.1289\n",
      "Epoch 14/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -20547.7910\n",
      "Epoch 14: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.14-t-20547.79-v-20087.33.hdf5\n",
      "\n",
      "Epoch 14:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0083, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0066\n",
      "Lambdas: []\n",
      "Validation Loss: -20087.330078125\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -20547.7910 - val_loss: -20087.3301\n",
      "Epoch 15/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -20471.5039\n",
      "Epoch 15: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.15-t-20471.50-v-19524.47.hdf5\n",
      "\n",
      "Epoch 15:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -19524.46875\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -20471.5039 - val_loss: -19524.4688\n",
      "Epoch 16/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -20810.0957\n",
      "Epoch 16: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.16-t-20810.10-v-20846.42.hdf5\n",
      "\n",
      "Epoch 16:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -20846.41796875\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -20810.0957 - val_loss: -20846.4180\n",
      "Epoch 17/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21068.9453\n",
      "Epoch 17: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.17-t-21068.95-v-21439.08.hdf5\n",
      "\n",
      "Epoch 17:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -21439.083984375\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -21068.9453 - val_loss: -21439.0840\n",
      "Epoch 18/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21304.5000\n",
      "Epoch 18: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.18-t-21304.50-v-22043.41.hdf5\n",
      "\n",
      "Epoch 18:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22043.40625\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -21304.5000 - val_loss: -22043.4062\n",
      "Epoch 19/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21364.7070\n",
      "Epoch 19: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.19-t-21364.71-v-21512.24.hdf5\n",
      "\n",
      "Epoch 19:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0117, 0.0134\n",
      "Overall sparsity: 0.0066\n",
      "Lambdas: []\n",
      "Validation Loss: -21512.23828125\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -21364.7070 - val_loss: -21512.2383\n",
      "Epoch 20/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21775.1270\n",
      "Epoch 20: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.20-t-21775.13-v-22288.36.hdf5\n",
      "\n",
      "Epoch 20:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -22288.359375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -21775.1270 - val_loss: -22288.3594\n",
      "Epoch 21/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21800.8945\n",
      "Epoch 21: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.21-t-21800.89-v-22448.51.hdf5\n",
      "\n",
      "Epoch 21:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0063, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -22448.505859375\n",
      "\n",
      "1419/1419 [==============================] - 113s 79ms/step - loss: -21800.8945 - val_loss: -22448.5059\n",
      "Epoch 22/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -21931.3828\n",
      "Epoch 22: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.22-t-21931.38-v-22018.15.hdf5\n",
      "\n",
      "Epoch 22:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -22018.1484375\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -21931.3828 - val_loss: -22018.1484\n",
      "Epoch 23/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22280.9863\n",
      "Epoch 23: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.23-t-22280.99-v-22552.61.hdf5\n",
      "\n",
      "Epoch 23:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -22552.607421875\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22280.9863 - val_loss: -22552.6074\n",
      "Epoch 24/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22208.6172\n",
      "Epoch 24: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.24-t-22208.62-v-22255.87.hdf5\n",
      "\n",
      "Epoch 24:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -22255.865234375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22208.6172 - val_loss: -22255.8652\n",
      "Epoch 25/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22213.1094\n",
      "Epoch 25: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.25-t-22213.11-v-22115.78.hdf5\n",
      "\n",
      "Epoch 25:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22115.779296875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -22213.1094 - val_loss: -22115.7793\n",
      "Epoch 26/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22296.8672\n",
      "Epoch 26: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.26-t-22296.87-v-22023.46.hdf5\n",
      "\n",
      "Epoch 26:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -22023.458984375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22296.8672 - val_loss: -22023.4590\n",
      "Epoch 27/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22168.9902\n",
      "Epoch 27: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.27-t-22168.99-v-20933.38.hdf5\n",
      "\n",
      "Epoch 27:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0007, 0.0078, 0.0089\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -20933.375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22168.9902 - val_loss: -20933.3750\n",
      "Epoch 28/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22079.6348\n",
      "Epoch 28: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.28-t-22079.63-v-22318.81.hdf5\n",
      "\n",
      "Epoch 28:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -22318.814453125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22079.6348 - val_loss: -22318.8145\n",
      "Epoch 29/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22233.7246\n",
      "Epoch 29: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.29-t-22233.72-v-22595.99.hdf5\n",
      "\n",
      "Epoch 29:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0020\n",
      "Lambdas: []\n",
      "Validation Loss: -22595.986328125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22233.7246 - val_loss: -22595.9863\n",
      "Epoch 30/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22290.6270\n",
      "Epoch 30: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.30-t-22290.63-v-23768.62.hdf5\n",
      "\n",
      "Epoch 30:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -23768.623046875\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22290.6270 - val_loss: -23768.6230\n",
      "Epoch 31/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22468.1992\n",
      "Epoch 31: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.31-t-22468.20-v-23065.25.hdf5\n",
      "\n",
      "Epoch 31:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23065.24609375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22468.1992 - val_loss: -23065.2461\n",
      "Epoch 32/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22664.8184\n",
      "Epoch 32: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.32-t-22664.82-v-23565.60.hdf5\n",
      "\n",
      "Epoch 32:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0020\n",
      "Lambdas: []\n",
      "Validation Loss: -23565.603515625\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22664.8184 - val_loss: -23565.6035\n",
      "Epoch 33/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22348.6758\n",
      "Epoch 33: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.33-t-22348.68-v-21666.72.hdf5\n",
      "\n",
      "Epoch 33:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0268\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -21666.71875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -22348.6758 - val_loss: -21666.7188\n",
      "Epoch 34/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22502.6309\n",
      "Epoch 34: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.34-t-22502.63-v-22848.91.hdf5\n",
      "\n",
      "Epoch 34:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0083, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -22848.90625\n",
      "\n",
      "1419/1419 [==============================] - 110s 77ms/step - loss: -22502.6309 - val_loss: -22848.9062\n",
      "Epoch 35/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22308.0293\n",
      "Epoch 35: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.35-t-22308.03-v-23520.88.hdf5\n",
      "\n",
      "Epoch 35:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -23520.876953125\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -22308.0293 - val_loss: -23520.8770\n",
      "Epoch 36/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22475.5391\n",
      "Epoch 36: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.36-t-22475.54-v-21502.00.hdf5\n",
      "\n",
      "Epoch 36:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0156, 0.0089\n",
      "Overall sparsity: 0.0071\n",
      "Lambdas: []\n",
      "Validation Loss: -21502.00390625\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -22475.5391 - val_loss: -21502.0039\n",
      "Epoch 37/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22597.0879\n",
      "Epoch 37: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.37-t-22597.09-v-23072.16.hdf5\n",
      "\n",
      "Epoch 37:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0076, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23072.1640625\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -22597.0879 - val_loss: -23072.1641\n",
      "Epoch 38/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22661.1621\n",
      "Epoch 38: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.38-t-22661.16-v-22466.29.hdf5\n",
      "\n",
      "Epoch 38:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -22466.294921875\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22661.1621 - val_loss: -22466.2949\n",
      "Epoch 39/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22849.8320\n",
      "Epoch 39: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.39-t-22849.83-v-23255.23.hdf5\n",
      "\n",
      "Epoch 39:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -23255.234375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -22849.8320 - val_loss: -23255.2344\n",
      "Epoch 40/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22867.1211\n",
      "Epoch 40: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.40-t-22867.12-v-23739.87.hdf5\n",
      "\n",
      "Epoch 40:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0078, 0.0134\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23739.87109375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22867.1211 - val_loss: -23739.8711\n",
      "Epoch 41/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22968.5156\n",
      "Epoch 41: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.41-t-22968.52-v-24078.76.hdf5\n",
      "\n",
      "Epoch 41:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -24078.7578125\n",
      "\n",
      "1419/1419 [==============================] - 113s 79ms/step - loss: -22968.5156 - val_loss: -24078.7578\n",
      "Epoch 42/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22908.4395\n",
      "Epoch 42: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.42-t-22908.44-v-23404.84.hdf5\n",
      "\n",
      "Epoch 42:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23404.841796875\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22908.4395 - val_loss: -23404.8418\n",
      "Epoch 43/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23011.1133\n",
      "Epoch 43: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.43-t-23011.11-v-24555.87.hdf5\n",
      "\n",
      "Epoch 43:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24555.869140625\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -23011.1133 - val_loss: -24555.8691\n",
      "Epoch 44/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23096.0762\n",
      "Epoch 44: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.44-t-23096.08-v-21412.16.hdf5\n",
      "\n",
      "Epoch 44:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0179\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -21412.1640625\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23096.0762 - val_loss: -21412.1641\n",
      "Epoch 45/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23189.6719\n",
      "Epoch 45: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.45-t-23189.67-v-23813.29.hdf5\n",
      "\n",
      "Epoch 45:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -23813.29296875\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23189.6719 - val_loss: -23813.2930\n",
      "Epoch 46/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22999.3750\n",
      "Epoch 46: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.46-t-22999.38-v-23034.69.hdf5\n",
      "\n",
      "Epoch 46:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23034.693359375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -22999.3750 - val_loss: -23034.6934\n",
      "Epoch 47/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -22980.7441\n",
      "Epoch 47: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.47-t-22980.74-v-22218.30.hdf5\n",
      "\n",
      "Epoch 47:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -22218.302734375\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -22980.7441 - val_loss: -22218.3027\n",
      "Epoch 48/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23079.4160\n",
      "Epoch 48: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.48-t-23079.42-v-23575.67.hdf5\n",
      "\n",
      "Epoch 48:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -23575.66796875\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -23079.4160 - val_loss: -23575.6680\n",
      "Epoch 49/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23178.7402\n",
      "Epoch 49: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.49-t-23178.74-v-23897.99.hdf5\n",
      "\n",
      "Epoch 49:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -23897.986328125\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23178.7402 - val_loss: -23897.9863\n",
      "Epoch 50/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23276.9414\n",
      "Epoch 50: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.50-t-23276.94-v-23271.21.hdf5\n",
      "\n",
      "Epoch 50:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23271.2109375\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -23276.9414 - val_loss: -23271.2109\n",
      "Epoch 51/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23168.0176\n",
      "Epoch 51: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.51-t-23168.02-v-23355.07.hdf5\n",
      "\n",
      "Epoch 51:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0156, 0.0134\n",
      "Overall sparsity: 0.0066\n",
      "Lambdas: []\n",
      "Validation Loss: -23355.07421875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23168.0176 - val_loss: -23355.0742\n",
      "Epoch 52/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23245.4316\n",
      "Epoch 52: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.52-t-23245.43-v-23633.99.hdf5\n",
      "\n",
      "Epoch 52:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0223\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23633.986328125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23245.4316 - val_loss: -23633.9863\n",
      "Epoch 53/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23393.6133\n",
      "Epoch 53: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.53-t-23393.61-v-19215.16.hdf5\n",
      "\n",
      "Epoch 53:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0039, 0.0179\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -19215.1640625\n",
      "\n",
      "1419/1419 [==============================] - 113s 79ms/step - loss: -23393.6133 - val_loss: -19215.1641\n",
      "Epoch 54/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23224.3262\n",
      "Epoch 54: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.54-t-23224.33-v-24059.07.hdf5\n",
      "\n",
      "Epoch 54:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24059.072265625\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -23224.3262 - val_loss: -24059.0723\n",
      "Epoch 55/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23568.9766\n",
      "Epoch 55: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.55-t-23568.98-v-24029.26.hdf5\n",
      "\n",
      "Epoch 55:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -24029.263671875\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -23568.9766 - val_loss: -24029.2637\n",
      "Epoch 56/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23653.9727\n",
      "Epoch 56: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.56-t-23653.97-v-23812.55.hdf5\n",
      "\n",
      "Epoch 56:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0063, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23812.546875\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -23653.9727 - val_loss: -23812.5469\n",
      "Epoch 57/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23657.4707\n",
      "Epoch 57: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.57-t-23657.47-v-23703.49.hdf5\n",
      "\n",
      "Epoch 57:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23703.490234375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23657.4707 - val_loss: -23703.4902\n",
      "Epoch 58/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23409.1914\n",
      "Epoch 58: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.58-t-23409.19-v-24018.66.hdf5\n",
      "\n",
      "Epoch 58:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0090, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0076\n",
      "Lambdas: []\n",
      "Validation Loss: -24018.66015625\n",
      "\n",
      "1419/1419 [==============================] - 126s 89ms/step - loss: -23409.1914 - val_loss: -24018.6602\n",
      "Epoch 59/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23179.0547\n",
      "Epoch 59: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.59-t-23179.05-v-21804.27.hdf5\n",
      "\n",
      "Epoch 59:\n",
      "Layer sparsities: 0.0000, 0.0400, 0.0042, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -21804.265625\n",
      "\n",
      "1419/1419 [==============================] - 124s 87ms/step - loss: -23179.0547 - val_loss: -21804.2656\n",
      "Epoch 60/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23735.6836\n",
      "Epoch 60: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.60-t-23735.68-v-23834.60.hdf5\n",
      "\n",
      "Epoch 60:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23834.59765625\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23735.6836 - val_loss: -23834.5977\n",
      "Epoch 61/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23630.9922\n",
      "Epoch 61: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.61-t-23630.99-v-23434.94.hdf5\n",
      "\n",
      "Epoch 61:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23434.94140625\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23630.9922 - val_loss: -23434.9414\n",
      "Epoch 62/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23546.0039\n",
      "Epoch 62: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.62-t-23546.00-v-24244.07.hdf5\n",
      "\n",
      "Epoch 62:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0007, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0015\n",
      "Lambdas: []\n",
      "Validation Loss: -24244.072265625\n",
      "\n",
      "1419/1419 [==============================] - 108s 76ms/step - loss: -23546.0039 - val_loss: -24244.0723\n",
      "Epoch 63/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23638.5234\n",
      "Epoch 63: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.63-t-23638.52-v-23635.88.hdf5\n",
      "\n",
      "Epoch 63:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0078, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23635.876953125\n",
      "\n",
      "1419/1419 [==============================] - 110s 77ms/step - loss: -23638.5234 - val_loss: -23635.8770\n",
      "Epoch 64/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23629.2051\n",
      "Epoch 64: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.64-t-23629.21-v-24248.89.hdf5\n",
      "\n",
      "Epoch 64:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24248.892578125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23629.2051 - val_loss: -24248.8926\n",
      "Epoch 65/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23517.2344\n",
      "Epoch 65: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.65-t-23517.23-v-23835.66.hdf5\n",
      "\n",
      "Epoch 65:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -23835.662109375\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23517.2344 - val_loss: -23835.6621\n",
      "Epoch 66/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23320.7734\n",
      "Epoch 66: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.66-t-23320.77-v-23695.52.hdf5\n",
      "\n",
      "Epoch 66:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0063, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23695.51953125\n",
      "\n",
      "1419/1419 [==============================] - 117s 82ms/step - loss: -23320.7734 - val_loss: -23695.5195\n",
      "Epoch 67/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23402.9375\n",
      "Epoch 67: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.67-t-23402.94-v-23872.19.hdf5\n",
      "\n",
      "Epoch 67:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23872.193359375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23402.9375 - val_loss: -23872.1934\n",
      "Epoch 68/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23317.4004\n",
      "Epoch 68: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.68-t-23317.40-v-22287.72.hdf5\n",
      "\n",
      "Epoch 68:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -22287.71875\n",
      "\n",
      "1419/1419 [==============================] - 117s 82ms/step - loss: -23317.4004 - val_loss: -22287.7188\n",
      "Epoch 69/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23371.3223\n",
      "Epoch 69: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.69-t-23371.32-v-23537.12.hdf5\n",
      "\n",
      "Epoch 69:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0223\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -23537.115234375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23371.3223 - val_loss: -23537.1152\n",
      "Epoch 70/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23547.7305\n",
      "Epoch 70: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.70-t-23547.73-v-24258.39.hdf5\n",
      "\n",
      "Epoch 70:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24258.388671875\n",
      "\n",
      "1419/1419 [==============================] - 118s 83ms/step - loss: -23547.7305 - val_loss: -24258.3887\n",
      "Epoch 71/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23899.1191\n",
      "Epoch 71: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.71-t-23899.12-v-22689.03.hdf5\n",
      "\n",
      "Epoch 71:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0078, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22689.03125\n",
      "\n",
      "1419/1419 [==============================] - 129s 91ms/step - loss: -23899.1191 - val_loss: -22689.0312\n",
      "Epoch 72/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23853.7266\n",
      "Epoch 72: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.72-t-23853.73-v-24015.09.hdf5\n",
      "\n",
      "Epoch 72:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -24015.087890625\n",
      "\n",
      "1419/1419 [==============================] - 113s 79ms/step - loss: -23853.7266 - val_loss: -24015.0879\n",
      "Epoch 73/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23693.3262\n",
      "Epoch 73: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.73-t-23693.33-v-21721.88.hdf5\n",
      "\n",
      "Epoch 73:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0117, 0.0089\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -21721.880859375\n",
      "\n",
      "1419/1419 [==============================] - 119s 84ms/step - loss: -23693.3262 - val_loss: -21721.8809\n",
      "Epoch 74/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23648.6211\n",
      "Epoch 74: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.74-t-23648.62-v-24985.09.hdf5\n",
      "\n",
      "Epoch 74:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24985.0859375\n",
      "\n",
      "1419/1419 [==============================] - 119s 84ms/step - loss: -23648.6211 - val_loss: -24985.0859\n",
      "Epoch 75/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23612.9863\n",
      "Epoch 75: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.75-t-23612.99-v-24383.66.hdf5\n",
      "\n",
      "Epoch 75:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24383.65625\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23612.9863 - val_loss: -24383.6562\n",
      "Epoch 76/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23708.7637\n",
      "Epoch 76: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.76-t-23708.76-v-23878.34.hdf5\n",
      "\n",
      "Epoch 76:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23878.3359375\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -23708.7637 - val_loss: -23878.3359\n",
      "Epoch 77/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23631.9336\n",
      "Epoch 77: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.77-t-23631.93-v-24229.47.hdf5\n",
      "\n",
      "Epoch 77:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0117, 0.0045\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24229.46875\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -23631.9336 - val_loss: -24229.4688\n",
      "Epoch 78/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23566.1035\n",
      "Epoch 78: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.78-t-23566.10-v-23386.64.hdf5\n",
      "\n",
      "Epoch 78:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23386.640625\n",
      "\n",
      "1419/1419 [==============================] - 110s 78ms/step - loss: -23566.1035 - val_loss: -23386.6406\n",
      "Epoch 79/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23567.1270\n",
      "Epoch 79: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.79-t-23567.13-v-24339.48.hdf5\n",
      "\n",
      "Epoch 79:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24339.484375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23567.1270 - val_loss: -24339.4844\n",
      "Epoch 80/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23546.6777\n",
      "Epoch 80: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.80-t-23546.68-v-23941.82.hdf5\n",
      "\n",
      "Epoch 80:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0078, 0.0089\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23941.81640625\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23546.6777 - val_loss: -23941.8164\n",
      "Epoch 81/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23611.4180\n",
      "Epoch 81: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.81-t-23611.42-v-23983.66.hdf5\n",
      "\n",
      "Epoch 81:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23983.66015625\n",
      "\n",
      "1419/1419 [==============================] - 113s 79ms/step - loss: -23611.4180 - val_loss: -23983.6602\n",
      "Epoch 82/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23531.1699\n",
      "Epoch 82: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.82-t-23531.17-v-23393.45.hdf5\n",
      "\n",
      "Epoch 82:\n",
      "Layer sparsities: 0.0000, 0.0400, 0.0042, 0.0078, 0.0000\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -23393.447265625\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -23531.1699 - val_loss: -23393.4473\n",
      "Epoch 83/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23063.8281\n",
      "Epoch 83: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.83-t-23063.83-v-18296.92.hdf5\n",
      "\n",
      "Epoch 83:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -18296.919921875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23063.8281 - val_loss: -18296.9199\n",
      "Epoch 84/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23200.4062\n",
      "Epoch 84: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.84-t-23200.41-v-24125.17.hdf5\n",
      "\n",
      "Epoch 84:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24125.166015625\n",
      "\n",
      "1419/1419 [==============================] - 111s 78ms/step - loss: -23200.4062 - val_loss: -24125.1660\n",
      "Epoch 85/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23153.2715\n",
      "Epoch 85: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.85-t-23153.27-v-23847.62.hdf5\n",
      "\n",
      "Epoch 85:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0223\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -23847.6171875\n",
      "\n",
      "1419/1419 [==============================] - 141s 100ms/step - loss: -23153.2715 - val_loss: -23847.6172\n",
      "Epoch 86/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23410.0957\n",
      "Epoch 86: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.86-t-23410.10-v-23920.23.hdf5\n",
      "\n",
      "Epoch 86:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -23920.228515625\n",
      "\n",
      "1419/1419 [==============================] - 118s 83ms/step - loss: -23410.0957 - val_loss: -23920.2285\n",
      "Epoch 87/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23151.2734\n",
      "Epoch 87: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.87-t-23151.27-v-19782.44.hdf5\n",
      "\n",
      "Epoch 87:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0015\n",
      "Lambdas: []\n",
      "Validation Loss: -19782.4375\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23151.2734 - val_loss: -19782.4375\n",
      "Epoch 88/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23516.4531\n",
      "Epoch 88: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.88-t-23516.45-v-24367.92.hdf5\n",
      "\n",
      "Epoch 88:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24367.921875\n",
      "\n",
      "1419/1419 [==============================] - 110s 77ms/step - loss: -23516.4531 - val_loss: -24367.9219\n",
      "Epoch 89/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23821.8008\n",
      "Epoch 89: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.89-t-23821.80-v-24554.33.hdf5\n",
      "\n",
      "Epoch 89:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0015\n",
      "Lambdas: []\n",
      "Validation Loss: -24554.328125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23821.8008 - val_loss: -24554.3281\n",
      "Epoch 90/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23769.9863\n",
      "Epoch 90: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.90-t-23769.99-v-24869.65.hdf5\n",
      "\n",
      "Epoch 90:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24869.646484375\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23769.9863 - val_loss: -24869.6465\n",
      "Epoch 91/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23943.7051\n",
      "Epoch 91: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.91-t-23943.71-v-21137.87.hdf5\n",
      "\n",
      "Epoch 91:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -21137.873046875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23943.7051 - val_loss: -21137.8730\n",
      "Epoch 92/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23898.0664\n",
      "Epoch 92: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.92-t-23898.07-v-22627.06.hdf5\n",
      "\n",
      "Epoch 92:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -22627.056640625\n",
      "\n",
      "1419/1419 [==============================] - 117s 83ms/step - loss: -23898.0664 - val_loss: -22627.0566\n",
      "Epoch 93/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23777.5879\n",
      "Epoch 93: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.93-t-23777.59-v-24352.65.hdf5\n",
      "\n",
      "Epoch 93:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0010\n",
      "Lambdas: []\n",
      "Validation Loss: -24352.650390625\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -23777.5879 - val_loss: -24352.6504\n",
      "Epoch 94/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23738.1992\n",
      "Epoch 94: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.94-t-23738.20-v-24487.18.hdf5\n",
      "\n",
      "Epoch 94:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24487.181640625\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23738.1992 - val_loss: -24487.1816\n",
      "Epoch 95/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23685.5605\n",
      "Epoch 95: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.95-t-23685.56-v-24254.38.hdf5\n",
      "\n",
      "Epoch 95:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24254.380859375\n",
      "\n",
      "1419/1419 [==============================] - 103s 73ms/step - loss: -23685.5605 - val_loss: -24254.3809\n",
      "Epoch 96/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23767.5859\n",
      "Epoch 96: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.96-t-23767.59-v-23574.70.hdf5\n",
      "\n",
      "Epoch 96:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23574.69921875\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -23767.5859 - val_loss: -23574.6992\n",
      "Epoch 97/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23758.4531\n",
      "Epoch 97: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.97-t-23758.45-v-23684.35.hdf5\n",
      "\n",
      "Epoch 97:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23684.345703125\n",
      "\n",
      "1419/1419 [==============================] - 111s 79ms/step - loss: -23758.4531 - val_loss: -23684.3457\n",
      "Epoch 98/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23604.3652\n",
      "Epoch 98: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.98-t-23604.37-v-24727.06.hdf5\n",
      "\n",
      "Epoch 98:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0063, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0066\n",
      "Lambdas: []\n",
      "Validation Loss: -24727.060546875\n",
      "\n",
      "1419/1419 [==============================] - 110s 77ms/step - loss: -23604.3652 - val_loss: -24727.0605\n",
      "Epoch 99/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23735.2383\n",
      "Epoch 99: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.99-t-23735.24-v-23528.96.hdf5\n",
      "\n",
      "Epoch 99:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0268\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23528.95703125\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23735.2383 - val_loss: -23528.9570\n",
      "Epoch 100/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23772.9336\n",
      "Epoch 100: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.100-t-23772.93-v-24775.41.hdf5\n",
      "\n",
      "Epoch 100:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -24775.41015625\n",
      "\n",
      "1419/1419 [==============================] - 104s 73ms/step - loss: -23772.9336 - val_loss: -24775.4102\n",
      "Epoch 101/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23624.5938\n",
      "Epoch 101: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.101-t-23624.59-v-22113.61.hdf5\n",
      "\n",
      "Epoch 101:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -22113.607421875\n",
      "\n",
      "1419/1419 [==============================] - 107s 75ms/step - loss: -23624.5938 - val_loss: -22113.6074\n",
      "Epoch 102/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23635.5898\n",
      "Epoch 102: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.102-t-23635.59-v-24855.04.hdf5\n",
      "\n",
      "Epoch 102:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0117, 0.0045\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24855.044921875\n",
      "\n",
      "1419/1419 [==============================] - 104s 73ms/step - loss: -23635.5898 - val_loss: -24855.0449\n",
      "Epoch 103/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23587.3750\n",
      "Epoch 103: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.103-t-23587.38-v-23283.99.hdf5\n",
      "\n",
      "Epoch 103:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0078, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23283.994140625\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -23587.3750 - val_loss: -23283.9941\n",
      "Epoch 104/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23644.2832\n",
      "Epoch 104: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.104-t-23644.28-v-22736.20.hdf5\n",
      "\n",
      "Epoch 104:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0078, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -22736.201171875\n",
      "\n",
      "1419/1419 [==============================] - 104s 73ms/step - loss: -23644.2832 - val_loss: -22736.2012\n",
      "Epoch 105/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23576.0391\n",
      "Epoch 105: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.105-t-23576.04-v-24415.58.hdf5\n",
      "\n",
      "Epoch 105:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0020\n",
      "Lambdas: []\n",
      "Validation Loss: -24415.576171875\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23576.0391 - val_loss: -24415.5762\n",
      "Epoch 106/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23553.3164\n",
      "Epoch 106: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.106-t-23553.32-v-23532.50.hdf5\n",
      "\n",
      "Epoch 106:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -23532.50390625\n",
      "\n",
      "1419/1419 [==============================] - 104s 73ms/step - loss: -23553.3164 - val_loss: -23532.5039\n",
      "Epoch 107/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23636.2949\n",
      "Epoch 107: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.107-t-23636.29-v-24991.33.hdf5\n",
      "\n",
      "Epoch 107:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0015\n",
      "Lambdas: []\n",
      "Validation Loss: -24991.328125\n",
      "\n",
      "1419/1419 [==============================] - 103s 72ms/step - loss: -23636.2949 - val_loss: -24991.3281\n",
      "Epoch 108/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23609.3203\n",
      "Epoch 108: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.108-t-23609.32-v-24013.93.hdf5\n",
      "\n",
      "Epoch 108:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0078, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -24013.9296875\n",
      "\n",
      "1419/1419 [==============================] - 106s 74ms/step - loss: -23609.3203 - val_loss: -24013.9297\n",
      "Epoch 109/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23543.0781\n",
      "Epoch 109: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.109-t-23543.08-v-24457.03.hdf5\n",
      "\n",
      "Epoch 109:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0014, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0020\n",
      "Lambdas: []\n",
      "Validation Loss: -24457.02734375\n",
      "\n",
      "1419/1419 [==============================] - 107s 75ms/step - loss: -23543.0781 - val_loss: -24457.0273\n",
      "Epoch 110/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23427.5957\n",
      "Epoch 110: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.110-t-23427.60-v-22156.79.hdf5\n",
      "\n",
      "Epoch 110:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0069, 0.0000, 0.0000\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22156.7890625\n",
      "\n",
      "1419/1419 [==============================] - 104s 74ms/step - loss: -23427.5957 - val_loss: -22156.7891\n",
      "Epoch 111/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23499.1660\n",
      "Epoch 111: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.111-t-23499.17-v-23251.65.hdf5\n",
      "\n",
      "Epoch 111:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0223\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -23251.6484375\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23499.1660 - val_loss: -23251.6484\n",
      "Epoch 112/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23671.1758\n",
      "Epoch 112: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.112-t-23671.18-v-25357.52.hdf5\n",
      "\n",
      "Epoch 112:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -25357.5234375\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23671.1758 - val_loss: -25357.5234\n",
      "Epoch 113/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23545.3105\n",
      "Epoch 113: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.113-t-23545.31-v-23335.64.hdf5\n",
      "\n",
      "Epoch 113:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0312\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -23335.642578125\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23545.3105 - val_loss: -23335.6426\n",
      "Epoch 114/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23885.9941\n",
      "Epoch 114: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.114-t-23885.99-v-24273.13.hdf5\n",
      "\n",
      "Epoch 114:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24273.126953125\n",
      "\n",
      "1419/1419 [==============================] - 107s 75ms/step - loss: -23885.9941 - val_loss: -24273.1270\n",
      "Epoch 115/1000\n",
      " 232/1419 [===>..........................] - ETA: 1:29 - loss: -23790.3770"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "                        x=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=[es, mcp, csv_logger, norms_and_loss_logger],\n",
    "                        epochs=1000,\n",
    "                        shuffle=False,\n",
    "                        verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb0e02f-a184-4214-acc6-307df5c014cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23969.5566\n",
      "Epoch 1: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.01-t-23969.56-v-23035.58.hdf5\n",
      "\n",
      "Epoch 1:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0061\n",
      "Lambdas: []\n",
      "Validation Loss: -23035.580078125\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23969.5566 - val_loss: -23035.5801\n",
      "Epoch 2/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23958.5527\n",
      "Epoch 2: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.02-t-23958.55-v-23828.70.hdf5\n",
      "\n",
      "Epoch 2:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0078, 0.0089\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -23828.6953125\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -23958.5527 - val_loss: -23828.6953\n",
      "Epoch 3/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24092.0566\n",
      "Epoch 3: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.03-t-24092.06-v-23316.58.hdf5\n",
      "\n",
      "Epoch 3:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -23316.578125\n",
      "\n",
      "1419/1419 [==============================] - 108s 76ms/step - loss: -24092.0566 - val_loss: -23316.5781\n",
      "Epoch 4/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23860.4512\n",
      "Epoch 4: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.04-t-23860.45-v-23649.26.hdf5\n",
      "\n",
      "Epoch 4:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -23649.26171875\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -23860.4512 - val_loss: -23649.2617\n",
      "Epoch 5/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23825.9688\n",
      "Epoch 5: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.05-t-23825.97-v-22464.70.hdf5\n",
      "\n",
      "Epoch 5:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22464.69921875\n",
      "\n",
      "1419/1419 [==============================] - 107s 75ms/step - loss: -23825.9688 - val_loss: -22464.6992\n",
      "Epoch 6/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23873.6523\n",
      "Epoch 6: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.06-t-23873.65-v-24463.54.hdf5\n",
      "\n",
      "Epoch 6:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0000\n",
      "Overall sparsity: 0.0025\n",
      "Lambdas: []\n",
      "Validation Loss: -24463.54296875\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -23873.6523 - val_loss: -24463.5430\n",
      "Epoch 7/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24058.3105\n",
      "Epoch 7: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.07-t-24058.31-v-24971.13.hdf5\n",
      "\n",
      "Epoch 7:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0179\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -24971.134765625\n",
      "\n",
      "1419/1419 [==============================] - 114s 81ms/step - loss: -24058.3105 - val_loss: -24971.1348\n",
      "Epoch 8/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23937.1973\n",
      "Epoch 8: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.08-t-23937.20-v-24942.97.hdf5\n",
      "\n",
      "Epoch 8:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0042, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -24942.96875\n",
      "\n",
      "1419/1419 [==============================] - 112s 79ms/step - loss: -23937.1973 - val_loss: -24942.9688\n",
      "Epoch 9/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23974.4297\n",
      "Epoch 9: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.09-t-23974.43-v-24839.95.hdf5\n",
      "\n",
      "Epoch 9:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0046\n",
      "Lambdas: []\n",
      "Validation Loss: -24839.94921875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23974.4297 - val_loss: -24839.9492\n",
      "Epoch 10/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23999.1367\n",
      "Epoch 10: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.10-t-23999.14-v-24074.09.hdf5\n",
      "\n",
      "Epoch 10:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0179\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24074.08984375\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -23999.1367 - val_loss: -24074.0898\n",
      "Epoch 11/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24134.7559\n",
      "Epoch 11: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.11-t-24134.76-v-24804.06.hdf5\n",
      "\n",
      "Epoch 11:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24804.056640625\n",
      "\n",
      "1419/1419 [==============================] - 107s 75ms/step - loss: -24134.7559 - val_loss: -24804.0566\n",
      "Epoch 12/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24115.7168\n",
      "Epoch 12: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.12-t-24115.72-v-23832.46.hdf5\n",
      "\n",
      "Epoch 12:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0223\n",
      "Overall sparsity: 0.0056\n",
      "Lambdas: []\n",
      "Validation Loss: -23832.46484375\n",
      "\n",
      "1419/1419 [==============================] - 106s 75ms/step - loss: -24115.7168 - val_loss: -23832.4648\n",
      "Epoch 13/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23971.2051\n",
      "Epoch 13: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.13-t-23971.21-v-22163.48.hdf5\n",
      "\n",
      "Epoch 13:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -22163.478515625\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -23971.2051 - val_loss: -22163.4785\n",
      "Epoch 14/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23969.0820\n",
      "Epoch 14: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.14-t-23969.08-v-25078.71.hdf5\n",
      "\n",
      "Epoch 14:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -25078.712890625\n",
      "\n",
      "1419/1419 [==============================] - 109s 77ms/step - loss: -23969.0820 - val_loss: -25078.7129\n",
      "Epoch 15/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23993.7207\n",
      "Epoch 15: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.15-t-23993.72-v-24150.26.hdf5\n",
      "\n",
      "Epoch 15:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24150.2578125\n",
      "\n",
      "1419/1419 [==============================] - 105s 74ms/step - loss: -23993.7207 - val_loss: -24150.2578\n",
      "Epoch 16/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23933.8789\n",
      "Epoch 16: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.16-t-23933.88-v-23557.79.hdf5\n",
      "\n",
      "Epoch 16:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -23557.78515625\n",
      "\n",
      "1419/1419 [==============================] - 104s 73ms/step - loss: -23933.8789 - val_loss: -23557.7852\n",
      "Epoch 17/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23942.4082\n",
      "Epoch 17: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.17-t-23942.41-v-24302.72.hdf5\n",
      "\n",
      "Epoch 17:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0069, 0.0039, 0.0179\n",
      "Overall sparsity: 0.0076\n",
      "Lambdas: []\n",
      "Validation Loss: -24302.71875\n",
      "\n",
      "1419/1419 [==============================] - 118s 83ms/step - loss: -23942.4082 - val_loss: -24302.7188\n",
      "Epoch 18/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23919.4805\n",
      "Epoch 18: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.18-t-23919.48-v-24042.15.hdf5\n",
      "\n",
      "Epoch 18:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0000, 0.0045\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -24042.1484375\n",
      "\n",
      "1419/1419 [==============================] - 113s 80ms/step - loss: -23919.4805 - val_loss: -24042.1484\n",
      "Epoch 19/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24127.6602\n",
      "Epoch 19: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.19-t-24127.66-v-24555.36.hdf5\n",
      "\n",
      "Epoch 19:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0049, 0.0117, 0.0000\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24555.359375\n",
      "\n",
      "1419/1419 [==============================] - 117s 82ms/step - loss: -24127.6602 - val_loss: -24555.3594\n",
      "Epoch 20/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24025.2578\n",
      "Epoch 20: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.20-t-24025.26-v-24628.51.hdf5\n",
      "\n",
      "Epoch 20:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0056, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0051\n",
      "Lambdas: []\n",
      "Validation Loss: -24628.505859375\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -24025.2578 - val_loss: -24628.5059\n",
      "Epoch 21/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24076.5703\n",
      "Epoch 21: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.21-t-24076.57-v-24722.02.hdf5\n",
      "\n",
      "Epoch 21:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0021, 0.0039, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -24722.021484375\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -24076.5703 - val_loss: -24722.0215\n",
      "Epoch 22/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24065.9277\n",
      "Epoch 22: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.22-t-24065.93-v-25539.73.hdf5\n",
      "\n",
      "Epoch 22:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0000, 0.0134\n",
      "Overall sparsity: 0.0036\n",
      "Lambdas: []\n",
      "Validation Loss: -25539.728515625\n",
      "\n",
      "1419/1419 [==============================] - 116s 82ms/step - loss: -24065.9277 - val_loss: -25539.7285\n",
      "Epoch 23/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -23976.4785\n",
      "Epoch 23: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.23-t-23976.48-v-24665.97.hdf5\n",
      "\n",
      "Epoch 23:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0028, 0.0039, 0.0045\n",
      "Overall sparsity: 0.0031\n",
      "Lambdas: []\n",
      "Validation Loss: -24665.96875\n",
      "\n",
      "1419/1419 [==============================] - 115s 81ms/step - loss: -23976.4785 - val_loss: -24665.9688\n",
      "Epoch 24/1000\n",
      "1419/1419 [==============================] - ETA: 0s - loss: -24015.9375\n",
      "Epoch 24: saving model to ./trained_models_non_mdmm/model-636eb1c6-checkpoints/weights.24-t-24015.94-v-24436.87.hdf5\n",
      "\n",
      "Epoch 24:\n",
      "Layer sparsities: 0.0000, 0.0000, 0.0035, 0.0039, 0.0089\n",
      "Overall sparsity: 0.0041\n",
      "Lambdas: []\n",
      "Validation Loss: -24436.8671875\n",
      "\n",
      "1419/1419 [==============================] - 114s 80ms/step - loss: -24015.9375 - val_loss: -24436.8672\n",
      "Epoch 25/1000\n",
      " 613/1419 [===========>..................] - ETA: 1:02 - loss: -23949.2539"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorms_and_loss_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "                        x=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=[es, mcp, csv_logger, norms_and_loss_logger],\n",
    "                        epochs=1000,\n",
    "                        shuffle=False,\n",
    "                        verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46850baa-d1eb-4bca-af6f-e8cde379d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model sparsity after Training (MDMM): { calculate_sparsity(mdmm_model.model, epsilon):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6e1f5-9e23-4067-980e-5659eb9ffab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_lmbdas = []\n",
    "current_inf = []\n",
    "for constraint in mdmm_model.constraints:\n",
    "    current_inf.append(constraint(x_dummy)) # x is a dummy actually\n",
    "    if hasattr(constraint, 'lmbda'):\n",
    "        current_lmbdas.append(constraint.lmbda.numpy())\n",
    "\n",
    "print(\"current_lmbdas:\", current_lmbdas)\n",
    "print(\"current_inf:\", current_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d3a38-c490-4ac2-9178-01e8381c171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d1523-05f1-45ce-b537-e9ca1ae92cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
